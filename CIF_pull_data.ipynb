{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "196264f5",
   "metadata": {},
   "source": [
    "# CIF Tools Jupyter Notebook\n",
    "\n",
    "The Jupyter Notebook version of `CIF_pull_data` allows you to compile the code by section more easily to help overcome issues with connectivity and long run times.\n",
    "\n",
    "1. The first section imports modules and let's you define your inputs to be used later in the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "648b1085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your default download folder for Google Chrome?: C:\\\\Users\\\\jtburu2\\\\Downloads\n",
      "What file contains your catchment area counties?: kansas_ca.csv\n",
      "Give a short name to identify your cancer center in save files: kumc\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\" \n",
    "Program to receive inputs and utilize CIFTools.py module\n",
    "for collection and curation of cancer rates and other related data.\n",
    "\"\"\"\n",
    "\n",
    "__authors__ = [\"Todd Burus, MAS\", \"Lee Park, MS\"]\n",
    "__copyright__ = \"Copyright 2022, University of Kentucky\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from io import StringIO\n",
    "from CIFTools import census_sdoh as sdoh\n",
    "from CIFTools import BLS\n",
    "from CIFTools import food_desert\n",
    "from CIFTools import fcc\n",
    "from CIFTools import facilities \n",
    "from CIFTools import water_violation\n",
    "from CIFTools import scp_cancer_data\n",
    "from CIFTools import places_data\n",
    "\n",
    "#################################################\n",
    "### customize paths and files before running  ###\n",
    "#################################################\n",
    "\n",
    "\n",
    "### input default download path for Chrome\n",
    "dl_path = input(r'What is your default download folder for Google Chrome?: ') # C:\\\\Users\\\\usr\\\\Downloads\\\\\n",
    "\n",
    "### input file name for catchment area county list\n",
    "ca_file = input(r'What file contains your catchment area counties?: ') # uky_ca.csv\n",
    "\n",
    "### input name of catchment area\n",
    "ca_name = input(r'Give a short name to identify your cancer center in save files: ') # Markey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070b64fb",
   "metadata": {},
   "source": [
    "2. Section 2 creates a table of US states with FIPS and postal codes and then sets up a handful of useful lists based on your catchment area file. *This section will not produce any output.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feb8c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "\n",
    "### create table and dataframe of states\n",
    "state = '''State,FIPS2,StateAbbrev\n",
    "Alabama,01,AL\n",
    "Alaska,02,AK\n",
    "Arizona,04,AZ\n",
    "Arkansas,05,AR\n",
    "California,06,CA\n",
    "Colorado,08,CO\n",
    "Connecticut,09,CT\n",
    "Delaware,10,DE\n",
    "District of Columbia,11,DC\n",
    "Florida,12,FL\n",
    "Georgia,13,GA\n",
    "Hawaii,15,HI\n",
    "Idaho,16,ID\n",
    "Illinois,17,IL\n",
    "Indiana,18,IN\n",
    "Iowa,19,IA\n",
    "Kansas,20,KS\n",
    "Kentucky,21,KY\n",
    "Louisiana,22,LA\n",
    "Maine,23,ME\n",
    "Maryland,24,MD\n",
    "Massachusetts,25,MA\n",
    "Michigan,26,MI\n",
    "Minnesota,27,MN\n",
    "Mississippi,28,MS\n",
    "Missouri,29,MO\n",
    "Montana,30,MT\n",
    "Nebraska,31,NE\n",
    "Nevada,32,NV\n",
    "New Hampshire,33,NH\n",
    "New Jersey,34,NJ\n",
    "New Mexico,35,NM\n",
    "New York,36,NY\n",
    "North Carolina,37,NC\n",
    "North Dakota,38,ND\n",
    "Ohio,39,OH\n",
    "Oklahoma,40,OK\n",
    "Oregon,41,OR\n",
    "Pennsylvania,42,PA\n",
    "Rhode Island,44,RI\n",
    "South Carolina,45,SC\n",
    "South Dakota,46,SD\n",
    "Tennessee,47,TN\n",
    "Texas,48,TX\n",
    "Utah,49,UT\n",
    "Vermont,50,VT\n",
    "Virginia,51,VA\n",
    "Washington,53,WA\n",
    "West Virginia,54,WV\n",
    "Wisconsin,55,WI\n",
    "Wyoming,56,WY\n",
    "'''\n",
    "\n",
    "dfCsv = StringIO(state)\n",
    "\n",
    "stateDf = pd.read_csv(dfCsv, sep=',', dtype={'State':str, 'FIPS2':str, 'StateAbbrev':str})\n",
    "\n",
    "### subset for catchment area\n",
    "ca = pd.read_csv(ca_file, dtype={'FIPS':str})\n",
    "ca = pd.merge(ca, stateDf, on='State', how='left')\n",
    "caState = ca.State.unique().tolist()\n",
    "caSA = ca.StateAbbrev.unique().tolist()\n",
    "caFIPS = ca.FIPS.unique().tolist()\n",
    "caFIPSint = [int(i) for i in caFIPS]\n",
    "caStateFIPS = ca.FIPS2.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1c2388",
   "metadata": {},
   "source": [
    "3. The third section pulls data from the US Census Bureau and US Bureau of Labor Statistics. This may take a few minutes depending on your catchment area and is subject to occasional timeout errors. It will generate status update outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "175b6d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting county-level Census data for 20\n",
      "Collecting county-level Census data for 29\n",
      "Collecting Census tract-level Census data for 20\n",
      "Collecting Census tract-level Census data for 29\n",
      "Collecting county-level labor statistics for 20\n",
      "Collecting county-level labor statistics for 29\n"
     ]
    }
   ],
   "source": [
    "### run county sdoh function for catchment area or all US counties\n",
    "sdoh_county_df = dict()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        for s in caStateFIPS:\n",
    "            print(f'Collecting county-level Census data for {s}')\n",
    "            sdoh_county = sdoh(region = 'County', state=s, run_query = True, year = 2021)\n",
    "            if len(sdoh_county_df) == 0:\n",
    "                sdoh_county_df = sdoh_county.sdoh_df\n",
    "            else:\n",
    "                for k, v in sdoh_county.sdoh_df.items():\n",
    "                    sdoh_county_df[k] = pd.concat([sdoh_county_df[k], \n",
    "                                                   sdoh_county.sdoh_df[k]])\n",
    "            del sdoh_county\n",
    "            for k, v in sdoh_county_df.items():\n",
    "                sdoh_county_df[k] = sdoh_county_df[k][sdoh_county_df[k]['FIPS'].isin(caFIPS)]\n",
    "    except NameError:\n",
    "        for s in stateDf.FIPS2:\n",
    "            sdoh_county = sdoh(region = 'County', state=s, run_query = True, year = 2021)\n",
    "            if len(sdoh_county_df) == 0:\n",
    "                sdoh_county_df = sdoh_county.sdoh_df\n",
    "            else:\n",
    "                for k, v in sdoh_county.sdoh_df.items():\n",
    "                    sdoh_county_df[k] = pd.concat([sdoh_county_df[k], sdoh_county.sdoh_df[k]])\n",
    "            del sdoh_county\n",
    "\n",
    "fips2county = sdoh_county_df['demo_all'][['FIPS', 'County']]\n",
    "            \n",
    "### run tract sdoh function for catchment area or all US Census tracts\n",
    "sdoh_tract_df = dict()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        for s in caStateFIPS:\n",
    "            print(f'Collecting Census tract-level Census data for {s}')\n",
    "            sdoh_tract = sdoh(region = 'Tract', state=s, run_query = True, year = 2021)\n",
    "            if len(sdoh_tract_df) == 0:\n",
    "                sdoh_tract_df = sdoh_tract.sdoh_df\n",
    "            else:\n",
    "                for k, v in sdoh_tract.sdoh_df.items():\n",
    "                    sdoh_tract_df[k] = pd.concat([sdoh_tract_df[k], sdoh_tract.sdoh_df[k]])\n",
    "            del sdoh_tract\n",
    "            for k, v in sdoh_tract_df.items():\n",
    "                sdoh_tract_df[k]['FIPS5'] = sdoh_tract_df[k]['FIPS'].str[0:5]\n",
    "                sdoh_tract_df[k] = sdoh_tract_df[k][sdoh_tract_df[k]['FIPS5'].isin(caFIPS)]\n",
    "                sdoh_tract_df[k] = sdoh_tract_df[k].drop(columns=['FIPS5'])\n",
    "    except NameError:\n",
    "        for s in stateDf.FIPS2:\n",
    "            sdoh_tract = sdoh(region = 'Tract', state=s, run_query = True, year = 2021)\n",
    "            if len(sdoh_tract_df) == 0:\n",
    "                sdoh_tract_df = sdoh_tract.sdoh_df\n",
    "            else:\n",
    "                for k, v in sdoh_tract.sdoh_df.items():\n",
    "                    sdoh_tract_df[k] = pd.concat([sdoh_tract_df[k], sdoh_tract.sdoh_df[k]])\n",
    "            del sdoh_tract\n",
    "\n",
    "\n",
    "### run county monthly unemployment for catchment area of all US counties\n",
    "bls_df = pd.DataFrame()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        for s in caStateFIPS:\n",
    "            print(f'Collecting county-level labor statistics for {s}')\n",
    "            bls = BLS(state = s)\n",
    "            bls.df[f'Monthly Unemployment Rate ({bls.df.Period.unique()[0]})'] = bls.df['Unemployment Rate']*0.01\n",
    "            bls.df = bls.df.drop(columns=['Unemployment Rate', 'Period'])\n",
    "            bls.df = bls.df[bls.df['FIPS'].isin(caFIPS)]\n",
    "            bls_df = pd.concat([bls_df, bls.df], ignore_index=True)\n",
    "            del bls\n",
    "    except NameError:\n",
    "        for s in stateDf.FIPS2:\n",
    "            bls = BLS(state = s)\n",
    "            bls.df[f'Monthly Unemployment Rate ({bls.df.Period.unique()[0]})'] = bls.df['Unemployment Rate']*0.01\n",
    "            bls.df = bls.df.drop(columns=['Unemployment Rate', 'Period'])\n",
    "            bls_df = pd.concat([bls_df, bls.df], ignore_index=True)\n",
    "            del bls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d64d612",
   "metadata": {},
   "source": [
    "4. Section 4 defines several functions for compiling and formatting data and writing it to file. *This section will not produce any output.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6846d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Define functions for curating data ############\n",
    "#################################################\n",
    "\n",
    "### economic data\n",
    "def gen_econ_data(countyDf = sdoh_county_df, tractDf = sdoh_tract_df):\n",
    "    print('Generating economic data tables...')\n",
    "    \n",
    "    econ_county = countyDf['demo_all'].loc[:, :'State'].sort_values('FIPS').reset_index(drop = True)\n",
    "    econ_tract = tractDf['demo_all'].loc[:, :'State'].sort_values('FIPS').reset_index(drop = True)\n",
    "    \n",
    "    # add insurnace\n",
    "    econ_county = econ_county.merge(countyDf['insurance'], on=['FIPS', 'County', 'State'], how='left')\n",
    "    econ_tract = econ_tract.merge(tractDf['insurance'], on=['FIPS', 'Tract', 'County', 'State'], how='left')  \n",
    "    \n",
    "    # add gini_index\n",
    "    econ_county = econ_county.merge(countyDf['gini_index'], on=['FIPS', 'County', 'State'], how='left')\n",
    "    econ_tract = econ_tract.merge(tractDf['gini_index'], on=['FIPS', 'Tract', 'County', 'State'], how='left')  \n",
    "    \n",
    "    # add median_household_income\n",
    "    econ_county = econ_county.merge(countyDf['income'].loc[:,:'median_income_all'],\\\n",
    "                                    on=['FIPS', 'County', 'State'], how='left')\n",
    "    econ_tract = econ_tract.merge(tractDf['income'].loc[:,:'median_income_all'],\\\n",
    "                                  on=['FIPS', 'Tract', 'County', 'State'], how='left')  \n",
    "    \n",
    "    # add annual_unemployment\n",
    "    econ_county = econ_county.merge(countyDf['employment'], on=['FIPS', 'County', 'State'], how='left')\n",
    "    econ_tract = econ_tract.merge(tractDf['employment'], on=['FIPS', 'Tract', 'County', 'State'], how='left')\n",
    "    \n",
    "    # add poverty\n",
    "    econ_county = econ_county.merge(countyDf['poverty'], on=['FIPS', 'County', 'State'], how='left')\n",
    "    econ_county = econ_county.drop(columns=['below_poverty_x.5', 'below_poverty_x2'])\n",
    "    \n",
    "    econ_tract = econ_tract.merge(tractDf['poverty'], on=['FIPS', 'Tract', 'County', 'State'], how='left')\n",
    "    econ_tract = econ_tract.drop(columns=['below_poverty_x.5', 'below_poverty_x2'])\n",
    "    \n",
    "    # rename columns\n",
    "    colnames = {'Labor Force Participation Rate': 'Annual Labor Force Participation Rate (2015-2019)',\n",
    "                'Unemployment Rate' : 'Annual Unemployment Rate (2015-2019)',\n",
    "                'health_insurance_coverage_rate': 'Insurance Coverage',\n",
    "                'Gini Index': 'Gini Coefficient',\n",
    "                'median_income_all': 'Household Income',\n",
    "                'medicaid' : 'Medicaid Enrollment',\n",
    "                'below_poverty' : 'Below Poverty'\n",
    "                }\n",
    "    \n",
    "    econ_county.rename(columns = colnames, inplace = True)\n",
    "    econ_tract.rename(columns = colnames, inplace = True)\n",
    "    \n",
    "    # calculate uninsured\n",
    "    econ_county['Uninsured'] = 1-econ_county['Insurance Coverage']\n",
    "    econ_tract['Uninsured'] = 1-econ_tract['Insurance Coverage']\n",
    "    \n",
    "    # monthly unemployment    \n",
    "    econ_county = econ_county.merge(bls_df, on='FIPS', how='left')\n",
    "    \n",
    "    return({'county': econ_county, 'tract':econ_tract})\n",
    "\n",
    "\n",
    "### housing and transportation data\n",
    "def gen_housing_transportation_data(countyDf = sdoh_county_df, tractDf = sdoh_tract_df):\n",
    "    print('Generating housing and transportation data tables...')\n",
    "    \n",
    "    # vacancy    \n",
    "    housing_county = countyDf['vacancy'].sort_values('FIPS').reset_index(drop = True)\n",
    "    housing_tract = tractDf['vacancy'].sort_values('FIPS').reset_index(drop = True)\n",
    "    \n",
    "    # transporation\n",
    "    housing_county = \\\n",
    "        housing_county.merge(countyDf['transportation'].loc[:,:'no_vehicle'], \\\n",
    "                             on=['FIPS', 'County', 'State'], how='left')\n",
    "    housing_tract = housing_tract.merge(tractDf['transportation'].loc[:,:'no_vehicle'], \\\n",
    "                                        on=['FIPS', 'Tract', 'County', 'State'], how='left')\n",
    "    \n",
    "    # rent_to_income\n",
    "    housing_county = housing_county.merge(countyDf['rent_to_income'], \\\n",
    "                                          on=['FIPS', 'County', 'State'], how='left')\n",
    "    housing_tract = housing_tract.merge(tractDf['rent_to_income'], \\\n",
    "                                        on=['FIPS', 'Tract', 'County', 'State'], how='left')\n",
    "    \n",
    "    housing_county.rename(columns = {'vacancy_rate': 'Vacancy Rate', 'no_vehicle': 'No Vehicle',\n",
    "                                     'rent_over_40':'Rent Burden (40% Income)'}, inplace = True)\n",
    "    housing_tract.rename(columns = {'vacancy_rate': 'Vacancy Rate', 'no_vehicle': 'No Vehicle',\n",
    "                                 'rent_over_40':'Rent Burden (40% Income)'}, inplace = True)\n",
    "    housing_county.sort_values('FIPS', inplace = True)\n",
    "    housing_tract.sort_values('FIPS', inplace = True)\n",
    "    return({'ht_county': housing_county, 'ht_tract': housing_tract})\n",
    "\n",
    "\n",
    "\n",
    "### sociodemographic data\n",
    "# create function to add race/ethnicity\n",
    "def add_race(table, sdoh_df, race):\n",
    "    table = table.sort_values('FIPS')\n",
    "    dat = sdoh_df[f'demo_{race}'].sort_values('FIPS')[['FIPS', 'total']].rename(columns={'total': f'{race}'})\n",
    "    table = table.merge(dat, on='FIPS', how='left')\n",
    "    return(table)\n",
    "\n",
    "# gather sociodemographic data\n",
    "def gen_sociodemographic_data(countyDf = sdoh_county_df, tractDf = sdoh_tract_df):\n",
    "    print('Generating sociodemographic data tables...')\n",
    "    \n",
    "    # population\n",
    "    sociodemo_county = countyDf['demo_total'].sort_values('FIPS').reset_index(drop = True)\n",
    "    sociodemo_tract = tractDf['demo_total'].sort_values('FIPS').reset_index(drop = True)\n",
    "    \n",
    "    #education\n",
    "    sociodemo_county = sociodemo_county.merge(countyDf['education'], \\\n",
    "                                              on=['FIPS', 'County', 'State'], how='left')\n",
    "    sociodemo_tract = sociodemo_tract.merge(tractDf['education'], \\\n",
    "                                            on=['FIPS', 'Tract', 'County', 'State'], how='left')\n",
    "    \n",
    "    # race/ethnicity\n",
    "    race = ['White','Black','Hispanic','Asian','Other_Races']\n",
    "    for r in race:\n",
    "        sociodemo_county = add_race(sociodemo_county, countyDf, r)\n",
    "        sociodemo_tract = add_race(sociodemo_tract, tractDf, r)\n",
    "    \n",
    "    # % rural\n",
    "    sociodemo_county = sociodemo_county.merge(countyDf['urban_rural'], \\\n",
    "                                              on=['FIPS', 'County', 'State'], how='left')\n",
    "    sociodemo_county.sort_values('FIPS', inplace = True)\n",
    "    sociodemo_tract.sort_values('FIPS', inplace = True)\n",
    "    return({'county': sociodemo_county, 'tract': sociodemo_tract})\n",
    "\n",
    "\n",
    "\n",
    "### gather location data\n",
    "def gen_location_data():\n",
    "    print('Collecting provider and facility location data...')\n",
    "    if not ca.empty:\n",
    "        place = caSA\n",
    "        place2 = caFIPS\n",
    "    else:\n",
    "        place = stateDf.StateAbbrev\n",
    "        place2 = stateDf.FIPS2\n",
    "\n",
    "    point_df = facilities()\n",
    "\n",
    "    print('Collecting Superfund sites data...')\n",
    "    point_df.superfund(location = caSA)\n",
    "    \n",
    "    print('Collecting Toxic Release Inventory data...')\n",
    "    point_df.toxRel(location = caSA)\n",
    "\n",
    "    print('Collecting HPSA facility data...')\n",
    "    point_df.hpsa(location = place2)\n",
    "\n",
    "    print('Collecting FQHC data...')\n",
    "    point_df.fqhc(location = place2)\n",
    "\n",
    "    print('Collecting provider data...')\n",
    "    point_df.nppes(location = place)\n",
    "\n",
    "    print('Collecting mammography facility data...')\n",
    "    point_df.mammography(state = place)\n",
    "\n",
    "    print('Collecting lung cancer screening facility data...')\n",
    "    point_df.lung_cancer_screening(download_path = dl_path, location = place)\n",
    "\n",
    "    sfs = point_df.superfund_df\n",
    "    sfs2 = sfs.loc[sfs.FIPS5.isin(caFIPSint)]\n",
    "    sfs2 = sfs2.drop(['FIPS5'], axis=1)\n",
    "    \n",
    "    tri = point_df.toxRel_df\n",
    "    f2c2 = fips2county\n",
    "    f2c2 = f2c2.assign(County = f2c2['County'].str.replace(' County', '').str.upper())\n",
    "    f2c2Dict = pd.Series(f2c2.FIPS.values, index=f2c2.County).to_dict()\n",
    "    tri2 = tri.replace(f2c2Dict)\n",
    "    tri3 = tri2.loc[tri2.COUNTY.isin(caFIPS)]\n",
    "    tri3 = tri3.drop(['COUNTY'], axis=1)\n",
    "\n",
    "    lcs = point_df.lung_cancer_screening_df\n",
    "    nppes = point_df.nppes_df\n",
    "    mammo = point_df.mammography_df\n",
    "    hpsa = point_df.hpsa_df\n",
    "    fqhc = point_df.fqhc_df\n",
    "    point_df = pd.concat([sfs2, tri3, lcs, nppes, mammo, hpsa, fqhc]).sort_values('Type')\n",
    "\n",
    "    return(point_df)\n",
    "\n",
    "\n",
    "    \n",
    "### gather environmental data\n",
    "def gen_env_data(water_violation_start_year = 2016):\n",
    "    print('Collecting environmental data...')\n",
    "    env_county = pd.DataFrame()\n",
    "    \n",
    "    # water violations\n",
    "    print('Collecting safe drinking water violations...')\n",
    "    for s in caSA:\n",
    "        water = water_violation(state = s, start_year = 2016) \n",
    "        env_county = pd.concat([env_county, water.df])\n",
    "    # env_county['FIPS'] = env_county.FIPS.astype(int)\n",
    "    env_county.rename(columns ={'counts': f'PWS_Violations_Since_{water_violation_start_year}' }, inplace = True)\n",
    "    env_county = env_county.merge(stateDf, on='StateAbbrev', how='left')\n",
    "    env_county = sdoh_county_df['poverty'].merge(env_county, on=['County', 'State'], how='left')\n",
    "    env_county = env_county[['FIPS', 'County', 'State', f'PWS_Violations_Since_{water_violation_start_year}']]\n",
    "   \n",
    "    # broadband speeds\n",
    "    print('Collecting broadband data...')\n",
    "    fcc_data = pd.DataFrame()\n",
    "    \n",
    "    for s in caSA:\n",
    "        FCC = fcc(state=s, download_path = dl_path) \n",
    "        fcc_data = pd.concat([fcc_data, FCC.fcc_data], ignore_index=True)\n",
    "        del FCC\n",
    "        \n",
    "    fcc_data['FIPS'] = fcc_data['BlockCode'].astype(str).str[:5]\n",
    "    fcc_data = fcc_data[fcc_data['FIPS'].isin(caFIPS)]\n",
    "    fcc_data = fcc_data.drop(columns='FIPS')\n",
    "    fcc_data = fcc_data.groupby(by = [\"BlockCode\"], as_index = False).mean()\n",
    "    fcc_data.rename(columns = {'MaxAdDown': 'avgMaxAdDown', 'MaxAdUp': 'avgMaxAdUp'}, inplace = True)\n",
    "    \n",
    "    # food_desert\n",
    "    print('Collecting food desert data...')\n",
    "    food  = food_desert(state = caState)\n",
    "    env_tract = food.food_desert\n",
    "    env_tract['Census_Tract_2019'] = env_tract.FIPS.astype(str).str.zfill(11)\n",
    "    env_tract['FIPS'] = env_tract['Census_Tract_2019'].str[:5]\n",
    "    env_tract = env_tract[['FIPS', 'Census_Tract_2019','LILATracts_Vehicle']]\n",
    "    env_tract = sdoh_county_df['poverty'].iloc[:,:3].merge(env_tract, on = 'FIPS', how='left')\n",
    "    env_tract.sort_values('FIPS', inplace = True)\n",
    "    \n",
    "    print('Aggregating food desert data to county-level...')\n",
    "    food.convert_region()\n",
    "    county_food = food.food_desert\n",
    "    county_food['FIPS'] = county_food.FIPS.astype(str).str.zfill(5)\n",
    "    env_county = env_county.iloc[:,:4].merge(county_food, on='FIPS', how='left')\n",
    "    env_county.sort_values('FIPS', inplace = True)\n",
    "    \n",
    "    return({'environment_county': env_county, 'environment_tract': env_tract,\n",
    "            'broadband_speeds': fcc_data})\n",
    "\n",
    "### gather cancer data\n",
    "def gen_cancer_data():\n",
    "    print('Collecting cancer incidence and mortality data...')\n",
    "    inc_data = pd.DataFrame()\n",
    "    mor_data = pd.DataFrame()\n",
    "    \n",
    "    for s in caStateFIPS:\n",
    "        cnr = scp_cancer_data(state = s)\n",
    "        inc_data = pd.concat([inc_data, cnr.incidence], ignore_index=True)\n",
    "        mor_data = pd.concat([mor_data, cnr.mortality], ignore_index=True)\n",
    "        del cnr\n",
    "    \n",
    "    inc_data = inc_data.merge(stateDf, on='FIPS2', how='left')\n",
    "    caInc = inc_data[['FIPS', 'County', 'State', 'Type', 'Site', 'AAR', 'AAC']]\n",
    "    caInc = caInc[caInc['FIPS'].isin(caFIPS)]\n",
    "    \n",
    "    mor_data = mor_data.merge(stateDf, on='FIPS2', how='left')\n",
    "    caMor = mor_data[['FIPS', 'County', 'State', 'Type', 'Site', 'AAR', 'AAC']]\n",
    "    caMor = caMor[caMor['FIPS'].isin(caFIPS)]\n",
    "    \n",
    "    return({'cancer_incidence': caInc, 'cancer_mortality': caMor})\n",
    "\n",
    "### gather CDC Places data\n",
    "def gen_places_data():\n",
    "    print('Collecting risk factor and screening data...')\n",
    "    places_county_data = pd.DataFrame()\n",
    "    places_tract_data = pd.DataFrame()\n",
    "\n",
    "    for s in caSA:\n",
    "        places = places_data(state = s)\n",
    "        places_county_data = pd.concat([places_county_data, places.county_est], ignore_index=True)\n",
    "        places_tract_data = pd.concat([places_tract_data, places.tract_est], ignore_index=True)\n",
    "        del places\n",
    "\n",
    "    short2long = pd.Series(stateDf.State.values, index=stateDf.StateAbbrev).to_dict()\n",
    "\n",
    "    places_county_data.drop(columns=['County'], axis=1, inplace=True)\n",
    "    places_county_data2 = places_county_data.merge(fips2county, on='FIPS', how='left')\n",
    "    places_county_data3 = places_county_data2.replace(short2long)\n",
    "    placesCounty = places_county_data3[places_county_data3['FIPS'].isin(caFIPS)]\n",
    "    col = placesCounty.pop('County')\n",
    "    placesCounty.insert(1, 'County', col)\n",
    "    placesCounty_l = pd.melt(placesCounty, id_vars=['FIPS', 'County', 'State'], \n",
    "                             var_name='measure', value_name='value')\n",
    "    placesCounty_l['value'] = pd.to_numeric(placesCounty_l['value'])/100\n",
    "\n",
    "    places_tract_data2 = places_tract_data.replace(short2long)\n",
    "    placesTract = places_tract_data2[places_tract_data2['FIPS5'].isin(caFIPS)]\n",
    "    placesTract = placesTract.drop(columns=['FIPS5'])\n",
    "    placesTract_l = pd.melt(placesTract, id_vars=['FIPS', 'County', 'State'],\n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    placesTract_l['value'] = pd.to_numeric(placesTract_l['value'])/100\n",
    "\n",
    "    return({'rfs_county': placesCounty_l, 'rfs_tract': placesTract_l})\n",
    "\n",
    "#################################################\n",
    "# Compile Data and Write to File ################\n",
    "#################################################\n",
    "\n",
    "### compile data\n",
    "def comp_data():\n",
    "    rfs = gen_places_data()\n",
    "    rfs_county_l, rfs_tract_l = rfs['rfs_county'], rfs['rfs_tract']\n",
    "    rfs_county = pd.pivot(rfs_county_l, index=['FIPS', 'County', 'State'], columns='measure', values='value')\n",
    "    rfs_tract = pd.pivot(rfs_tract_l, index=['FIPS', 'County', 'State'], columns='measure', values='value')\n",
    "    cancer = gen_cancer_data()\n",
    "    cancer_inc_l, cancer_mor_l = cancer['cancer_incidence'], cancer['cancer_mortality']\n",
    "    cancer_inc = pd.pivot(cancer_inc_l, index=['FIPS', 'County', 'State', 'Type'], columns='Site', values='AAR')\n",
    "    cancer_mor = pd.pivot(cancer_mor_l, index=['FIPS', 'County', 'State', 'Type'], columns='Site', values='AAR')\n",
    "    econ = gen_econ_data()\n",
    "    econ_county, econ_tract = econ['county'], econ['tract']\n",
    "    econ_county_l = pd.melt(econ_county, id_vars = ['FIPS', 'County', 'State'], \n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    econ_tract_l = pd.melt(econ_tract, id_vars = ['FIPS', 'Tract', 'County', 'State'], \n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    housing_transportation = gen_housing_transportation_data()\n",
    "    ht_county, ht_tract = housing_transportation['ht_county'], housing_transportation['ht_tract']\n",
    "    ht_county_l = pd.melt(ht_county, id_vars = ['FIPS', 'County', 'State'], \n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    ht_tract_l = pd.melt(ht_tract, id_vars = ['FIPS', 'Tract', 'County', 'State'], \n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    sociodemo = gen_sociodemographic_data()\n",
    "    sociodemo_county, sociodemo_tract = sociodemo['county'], sociodemo['tract']\n",
    "    sd_county_l = pd.melt(sociodemo_county, id_vars = ['FIPS', 'County', 'State'], \n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    sd_tract_l = pd.melt(sociodemo_tract, id_vars = ['FIPS', 'Tract', 'County', 'State'], \n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    env = gen_env_data()\n",
    "    env_county, env_tract, broadband_data = env['environment_county'], env['environment_tract'], env['broadband_speeds']\n",
    "    env_county_l = pd.melt(env_county, id_vars = ['FIPS', 'County', 'State'], \n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    env_tract_l = pd.melt(env_tract, id_vars = ['FIPS', 'County', 'State', 'Census_Tract_2019'], \n",
    "                            var_name = 'measure', value_name = 'value')\n",
    "    point_df = gen_location_data()\n",
    "\n",
    "    return({'rf_and_screening_county': rfs_county, 'rf_and_screening_county_long': rfs_county_l,\n",
    "            'rf_and_screening_tract': rfs_tract, 'rf_and_screening_tract_long': rfs_tract_l,\n",
    "            'cancer_incidence': cancer_inc, 'cancer_incidence_long': cancer_inc_l,\n",
    "            'cancer_mortality': cancer_mor, 'cancer_mortality_long': cancer_mor_l,\n",
    "            'economy_county': econ_county, 'economy_county_long': econ_county_l,\n",
    "            'economy_tract': econ_tract, 'economy_tract_long': econ_tract_l,\n",
    "            'ht_county': ht_county, 'ht_county_long': ht_county_l, \n",
    "            'ht_tract': ht_tract, 'ht_tract_long': ht_tract_l, \n",
    "            'sociodemographics_county': sociodemo_county, 'sd_county_long': sd_county_l,\n",
    "            'sociodemographics_tract': sociodemo_tract, 'sd_tract_long': sd_tract_l,\n",
    "            'environment_county': env_county, 'environment_county_long': env_county_l,\n",
    "            'environment_tract': env_tract, 'environment_tract_long': env_tract_l,\n",
    "            'broadband_speeds': broadband_data, 'facilities_and_providers': point_df})\n",
    "\n",
    "### write data to Excel\n",
    "def save_as_xlsx():\n",
    "    from pandas import ExcelWriter\n",
    "    from datetime import datetime as dt\n",
    "    \n",
    "    ca_dir = ca_name.replace(\" \", \"_\") + \"_catchment_data\"\n",
    "    path2 = os.path.join(os.getcwd(), ca_dir)\n",
    "    \n",
    "    if os.path.exists(path2) == False:\n",
    "        os.makedirs(path2)\n",
    "        \n",
    "    save_name = ca_name.replace(\" \", \"_\") + '_catchment_data_' + dt.today().strftime('%m-%d-%Y') + '.xlsx'\n",
    "    save_name2 = ca_name.replace(\" \", \"_\") + '_catchment_data_long_' + dt.today().strftime('%m-%d-%Y') + '.xlsx'\n",
    "    full_path = os.path.join(os.getcwd(), ca_dir, save_name)\n",
    "    full_path2 = os.path.join(os.getcwd(), ca_dir, save_name2)\n",
    "\n",
    "    with ExcelWriter(full_path, mode = 'w') as writer:\n",
    "        print('Writing data to file...')\n",
    "        pd.read_csv('CIFTools_Documentation.csv', \n",
    "                    header = None, encoding = \"ISO-8859-1\").to_excel(writer, header = None, \n",
    "                                                                     sheet_name = 'Variables and Sources', index = False)\n",
    "        cdata['cancer_incidence'].to_excel(writer, sheet_name = 'Cancer Incidence', index = True)\n",
    "        cdata['cancer_mortality'].to_excel(writer, sheet_name = 'Cancer Mortality', index = True)\n",
    "        cdata['economy_county'].to_excel(writer, sheet_name = 'Economy (County)', index = False)\n",
    "        cdata['economy_tract'].to_excel(writer, sheet_name = 'Economy (Tract)', index = False)\n",
    "        cdata['environment_county'].to_excel(writer, sheet_name = 'Environment (County)', index = False)\n",
    "        cdata['environment_tract'].to_excel(writer, sheet_name = 'Environment (Tract)', index = False)\n",
    "        #cdata['broadband_speeds'].to_excel(writer, sheet_name = 'Broadband Speeds', index = False) #can be too long in some areas\n",
    "        cdata['ht_county'].to_excel(writer, sheet_name = 'H and T (County)', index = False)\n",
    "        cdata['ht_tract'].to_excel(writer, sheet_name= 'H and T (Tract)', index = False)\n",
    "        cdata['rf_and_screening_county'].to_excel(writer, sheet_name= 'RF and Screening (County)', index=True)\n",
    "        cdata['rf_and_screening_tract'].to_excel(writer, sheet_name= 'RF and Screening (Tract)', index=True)\n",
    "        cdata['sociodemographics_county'].to_excel(writer, sheet_name = 'Sociodemographic (County)', index = False)\n",
    "        cdata['sociodemographics_tract'].to_excel(writer, sheet_name = 'Sociodemographic (Tract)', index = False)\n",
    "        cdata['facilities_and_providers'].to_excel(writer, sheet_name = 'Facilities', index = False)\n",
    "        \n",
    "    with ExcelWriter(full_path2, mode = 'w') as writer:\n",
    "        print('Writing data to file...')\n",
    "        pd.read_csv('CIFTools_Documentation.csv', \n",
    "                    header = None, encoding = \"ISO-8859-1\").to_excel(writer, header = None, \n",
    "                                                                     sheet_name = 'Variables and Sources', index = False)\n",
    "        cdata['cancer_incidence_long'].to_excel(writer, sheet_name = 'Cancer Incidence', index = True)\n",
    "        cdata['cancer_mortality_long'].to_excel(writer, sheet_name = 'Cancer Mortality', index = True)\n",
    "        cdata['economy_county_long'].to_excel(writer, sheet_name = 'Economy (County)', index = False)\n",
    "        cdata['economy_tract_long'].to_excel(writer, sheet_name = 'Economy (Tract)', index = False)\n",
    "        cdata['environment_county_long'].to_excel(writer, sheet_name = 'Environment (County)', index = False)\n",
    "        cdata['environment_tract_long'].to_excel(writer, sheet_name = 'Environment (Tract)', index = False)\n",
    "        #cdata['broadband_speeds'].to_excel(writer, sheet_name = 'Broadband Speeds', index = False) # can be too long in some areas\n",
    "        cdata['ht_county_long'].to_excel(writer, sheet_name = 'H and T (County)', index = False)\n",
    "        cdata['ht_tract_long'].to_excel(writer, sheet_name= 'H and T (Tract)', index = False)\n",
    "        cdata['rf_and_screening_county_long'].to_excel(writer, sheet_name= 'RF and Screening (County)', \n",
    "                                                        index=True)\n",
    "        cdata['rf_and_screening_tract_long'].to_excel(writer, sheet_name= 'RF and Screening (Tract)', \n",
    "                                                      index=True)\n",
    "        cdata['sd_county_long'].to_excel(writer, sheet_name = 'Sociodemographic (County)', index = False)\n",
    "        cdata['sd_tract_long'].to_excel(writer, sheet_name = 'Sociodemographic (Tract)', index = False)\n",
    "        cdata['facilities_and_providers'].to_excel(writer, sheet_name = 'Facilities', index = False)\n",
    "    \n",
    "    print(save_name + ' created')\n",
    "    \n",
    "    return\n",
    "\n",
    "### write data to CSVs\n",
    "def save_as_csvs():\n",
    "    from datetime import datetime as dt\n",
    "    today = dt.today().strftime('%m-%d-%Y')\n",
    "    ca_dir = ca_name.replace(\" \", \"_\") + \"_catchment_data\"\n",
    "    path2 = os.path.join(os.getcwd(), ca_dir)\n",
    "    \n",
    "    if os.path.exists(path2) == False:\n",
    "        os.makedirs(path2)\n",
    "        \n",
    "    os.chdir(path2)\n",
    "    \n",
    "    cdata['cancer_incidence'].to_csv(ca_name + '_cancer_incidence_county_' + today + '.csv', encoding='utf-8', index=True)\n",
    "    cdata['cancer_mortality'].to_csv(ca_name + '_cancer_mortality_county_' + today + '.csv', encoding='utf-8', index=True)\n",
    "    cdata['cancer_incidence_long'].to_csv(ca_name + '_cancer_incidence_county_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['cancer_mortality_long'].to_csv(ca_name + '_cancer_mortality_county_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['economy_county'].to_csv(ca_name + '_economy_county_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['economy_county_long'].to_csv(ca_name + '_economy_county_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['economy_tract'].to_csv(ca_name + '_economy_tract_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['economy_tract_long'].to_csv(ca_name + '_economy_tract_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['environment_county'].to_csv(ca_name + '_environment_county_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['environment_county_long'].to_csv(ca_name + '_environment_county_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['environment_tract'].to_csv(ca_name + '_environment_tract_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['environment_tract_long'].to_csv(ca_name + '_environment_tract_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['ht_county'].to_csv(ca_name + '_housing_trans_county_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['ht_county_long'].to_csv(ca_name + '_housing_trans_county_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['ht_tract'].to_csv(ca_name + '_housing_trans_tract_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['ht_tract_long'].to_csv(ca_name + '_housing_trans_tract_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['rf_and_screening_county'].to_csv(ca_name + '_rf_and_screening_county_' + today + '.csv', encoding='utf-8', index=True)\n",
    "    cdata['rf_and_screening_tract'].to_csv(ca_name + '_rf_and_screening_tract_' + today + '.csv', encoding='utf-8', index=True)\n",
    "    cdata['rf_and_screening_county_long'].to_csv(ca_name + '_rf_and_screening_county_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['rf_and_screening_tract_long'].to_csv(ca_name + '_rf_and_screening_tract_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['sociodemographics_county'].to_csv(ca_name + '_sociodemographics_county_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['sd_county_long'].to_csv(ca_name + '_sociodemographics_county_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['sociodemographics_tract'].to_csv(ca_name + '_sociodemographics_tract_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['sd_tract_long'].to_csv(ca_name + '_sociodemographics_tract_long_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['broadband_speeds'].to_csv(ca_name + '_broadband_speeds_' + today + '.csv', encoding='utf-8', index=False)\n",
    "    cdata['facilities_and_providers'].to_csv(ca_name + '_facilities_and_providers_' + today + '.csv', encoding='utf-8', index=False)\n",
    "\n",
    "    print('Success! CSVs created')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06728e70",
   "metadata": {},
   "source": [
    "5. The final section runs the formatting and writing functions. This section will take the longest to run and will occasionally run into timeout errors. A couple of automated Chrome browsers will open along the way for automatically scraping data from the internet (the exact number depends on the number of unique states in your catchment). Status update outputs will generate along the way, including a message indicating successful writing of datasets to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b022d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting risk factor and screening data...\n",
      "Collecting cancer incidence and mortality data...\n",
      "Generating economic data tables...\n",
      "Generating housing and transportation data tables...\n",
      "Generating sociodemographic data tables...\n",
      "Collecting environmental data...\n",
      "Collecting safe drinking water violations...\n",
      "Collecting broadband data...\n",
      "Waiting on KS broadband data...\n",
      "KS broadband data ready\n",
      "Waiting on MO broadband data...\n",
      "Waiting on MO broadband data...\n",
      "MO broadband data ready\n",
      "Collecting food desert data...\n",
      "Aggregating food desert data to county-level...\n",
      "Collecting provider and facility location data...\n",
      "Collecting Superfund sites data...\n",
      "Collecting Toxic Release Inventory data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jtburu2\\CIFData\\CIFTools.py:1145: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  tri.columns = tri.columns.str.replace(r'^[0-9]+.\\s', '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting HPSA facility data...\n",
      "Collecting FQHC data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jtburu2\\CIFData\\CIFTools.py:1203: DtypeWarning: Columns (52,54,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df= pd.read_csv('https://data.hrsa.gov//DataDownload/DD_Files/Health_Center_Service_Delivery_and_LookAlike_Sites.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting provider data...\n",
      "Collecting mammography facility data...\n",
      "Collecting lung cancer screening facility data...\n",
      "Waiting on LCSR data...\n",
      "Waiting on LCSR data...\n",
      "LCSR data ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jtburu2\\AppData\\Local\\Temp\\ipykernel_22276\\953705541.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sfs2.drop(['FIPS5'], axis=1, inplace=True)\n",
      "C:\\Users\\jtburu2\\AppData\\Local\\Temp\\ipykernel_22276\\953705541.py:171: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tri3.drop(['COUNTY'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! CSVs created\n"
     ]
    }
   ],
   "source": [
    "# run compile and write functions\n",
    "if __name__ == '__main__':\n",
    "    cdata = comp_data()  \n",
    "    #save_as_xlsx()\n",
    "    save_as_csvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff25cf2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
